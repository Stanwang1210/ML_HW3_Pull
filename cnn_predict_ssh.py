# -*- coding: utf-8 -*-
"""CNN_predict_ssh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c1N7jjIJuamySLG_iobRHdRLmwn-s1Ww
"""

from google.colab import drive

drive.mount('/content/drive')

ls

cd 'drive'

ls

cd 'My Drive'

ls

cd 'HW3 Data'

ls

# Import需要的套件
from torchsummary import summary
import os
import numpy as np
import cv2
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import pandas as pd
from torch.utils.data import DataLoader, Dataset
import time
import sys

"""#Read image
利用 OpenCV (cv2) 讀入照片並存放在 numpy array 中
"""

def readfile(path, label):
    # label 是一個 boolean variable，代表需不需要回傳 y 值
    image_dir = sorted(os.listdir(path))
    x = np.zeros((len(image_dir), 128, 128, 3), dtype=np.uint8)
    y = np.zeros((len(image_dir)), dtype=np.uint8)
    for i, file in enumerate(image_dir):
        img = cv2.imread(os.path.join(path, file))
        x[i, :, :] = cv2.resize(img,(128, 128))
        if label:
          y[i] = int(file.split("_")[0])
    if label:
      return x, y
    else:
      return x

#分別將 training set、validation set、testing set 用 readfile 函式讀進來
'''
workspace_dir = sys.argv[1]
MODLE_PATH = "model_params/best_model3.pt"
print("Reading data")

test_x = readfile(os.path.join(workspace_dir, "testing"), False)
print("Size of Testing data = {}".format(len(test_x)))
'''
MODLE_PATH = 'model_best.pt'
test_x = np.load('test_x.npy')

print("Loading mean")
my_mean = np.load("mean.npy")
print("mean loaded")
print("Loading std")
my_std = np.load("std.npy")
print("std loaded")

#training 時做 data augmentation
train_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.RandomHorizontalFlip(), #隨機將圖片水平翻轉
    transforms.RandomRotation(15), #隨機旋轉圖片
    transforms.ToTensor(), #將圖片轉成 Tensor，並把數值normalize到[0,1](data normalization)
    transforms.Normalize(my_mean,my_std),
])
#testing 時不需做 data augmentation
test_transform = transforms.Compose([
    transforms.ToPILImage(),                                    
    transforms.ToTensor(),
    transforms.Normalize(my_mean,my_std),
])
class ImgDataset(Dataset):
    def __init__(self, x, y=None, transform=None):
        self.x = x
        # label is required to be a LongTensor
        self.y = y
        if y is not None:
            self.y = torch.LongTensor(y)
        self.transform = transform
    def __len__(self):
        return len(self.x)
    def __getitem__(self, index):
        X = self.x[index]
        if self.transform is not None:
            X = self.transform(X)
        if self.y is not None:
            Y = self.y[index]
            return X, Y
        else:
            return X

batch_size = 128#128





"""# Model"""

class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        #torch.nn.MaxPool2d(kernel_size, stride, padding)
        #input 維度 [3, 128, 128]
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.03),
            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]
            nn.Dropout(0.2),

            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.03),
            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]
            nn.Dropout(0.2),

            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.03),
            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]
            nn.Dropout(0.2),

            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.03),
            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]
            nn.Dropout(0.2),
            
            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.03),
            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]
            nn.Dropout(0.2),

            nn.Conv2d(512, 512, 3, 1, 1), # [512, 4, 4]
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.03),
            nn.MaxPool2d(2, 2, 0),       # [512, 2, 2]
            nn.Dropout(0.2),

            nn.Conv2d(512, 512, 3, 1, 1), # [512, 4, 4]
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.03),
            nn.MaxPool2d(2, 2, 0),       # [512, 1, 1]
            nn.Dropout(0.2),

            
        )
        self.fc = nn.Sequential(
            # nn.Linear(512, 1024),
            # #nn.Dropout(0.1),
            # nn.LeakyReLU(0.03),
            # nn.Linear(1024, 512),
            # #nn.Dropout(0.1),
            # nn.LeakyReLU(0.03),
            # nn.Linear(512, 256),
            # nn.Dropout(0.2),
            # nn.LeakyReLU(0.03),
            # nn.Linear(256, 128),
            # nn.Dropout(0.2),
            # nn.LeakyReLU(0.03),
            # nn.Linear(128, 11)
            nn.Linear(512,256), #nn.linear(dim of input, dim of output)
            nn.LeakyReLU(0.03),
            nn.Dropout(0.2),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 11)
        )

    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1)
        return self.fc(out)



model_best = Classifier().cuda()
print("Loading model...")
model_best.load_state_dict(torch.load(MODLE_PATH))
print("Model(" + MODLE_PATH+ ") loaded")

"""# Testing
利用剛剛 train 好的 model 進行 prediction
"""

test_set = ImgDataset(test_x, transform=test_transform)
test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)

model_best.eval()
prediction = []
with torch.no_grad():
    for i, data in enumerate(test_loader):
        test_pred = model_best(data.cuda())
        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)
        for y in test_label:
            prediction.append(y)
sys.argv[2] = 'CNN_predict.csv'
#將結果寫入 csv 檔
with open(sys.argv[2], 'w') as f:
    f.write('Id,Category\n')
    for i, y in  enumerate(prediction):
        f.write('{},{}\n'.format(i, y))
print("Prediction Done")
print(sys.argv[2] + " saved")



from google.colab import files

files.download(sys.argv[2])